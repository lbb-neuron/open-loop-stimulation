{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(file_pre,filename,overwrite=False):\n",
    "    # Create the file, if it does not exist yet\n",
    "    if os.path.exists(filename):\n",
    "        if (overwrite == False):\n",
    "            print('File does already exist. Do nothing')\n",
    "            return\n",
    "        else:\n",
    "            print('File does already exist. Overwrite.')\n",
    "            \n",
    "    file_index  = 0\n",
    "    f_read      = h5py.File(file_pre + str(file_index).zfill(4) + \".h5\",'r')\n",
    "    file_length = len(f_read['circuit_0'].keys())\n",
    "    file_loc    = [0]*15\n",
    "\n",
    "    def get_next_data(circuit_id,f_read,file_index,file_length,file_loc):\n",
    "        data    = f_read['circuit_'+str(circuit_id)+'/event_'+str(file_loc[circuit_id])]\n",
    "        data    = {'pattern'  : np.array(data['pattern_0']),\n",
    "                   'spikes_1' : np.array(data['spikes_1']),\n",
    "                   'spikes_2' : np.array(data['spikes_2']),\n",
    "                   'spikes_3' : np.array(data['spikes_3']),\n",
    "                   'spikes_4' : np.array(data['spikes_4'])}\n",
    "        file_loc[circuit_id] = file_loc[circuit_id] + 1\n",
    "\n",
    "        if circuit_id == 14 and file_loc[circuit_id] == file_length:\n",
    "            f_read.close()\n",
    "            file_index = file_index + 1\n",
    "               \n",
    "            try:\n",
    "                f_read      = h5py.File(file_pre + str(file_index).zfill(4) + \".h5\",'r')\n",
    "                file_length = file_length + len(f_read['circuit_0'].keys())\n",
    "            except:\n",
    "                print('\\n\\rAll files read out')\n",
    "                return data,  True,   None,    None,        None,         None\n",
    "\n",
    "        return         data,  False,  f_read,  file_index,  file_length,  file_loc\n",
    "    \n",
    "    unit_length  = 512\n",
    "\n",
    "    raw_patterns = []\n",
    "    for i in range(15):\n",
    "        raw_patterns.append([]) # stim_ID, pattern_ID\n",
    "        raw_patterns[i].append([])\n",
    "\n",
    "    raw_spikes   = []\n",
    "    for i in range(15):\n",
    "        raw_spikes.append([]) # stim_ID, elec_ID, time_after_stim\n",
    "        raw_spikes[i].append([])\n",
    "        \n",
    "    running_count = 0\n",
    "    flag = True\n",
    "    while flag:\n",
    "        print(running_count,end='\\r')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # Get next data point\n",
    "        for i in range(15):        \n",
    "            data,done,f_read,file_index,file_length,file_loc = get_next_data(i,f_read,file_index,file_length,file_loc)\n",
    "\n",
    "            flag = not done\n",
    "\n",
    "            pattern = data['pattern']\n",
    "\n",
    "            if len(raw_patterns[i][-1]) > unit_length:\n",
    "                raw_patterns[i].append([])\n",
    "            raw_patterns[i][-1].append([running_count,int(pattern)])\n",
    "\n",
    "            for j in range(4):\n",
    "                list_spikes_j = data['spikes_'+str(j+1)].tolist()\n",
    "                for element in list_spikes_j:\n",
    "                    if len(raw_spikes[i][-1]) > unit_length:\n",
    "                        raw_spikes[i].append([])\n",
    "                    raw_spikes[i][-1].append([running_count,j,element])\n",
    "        running_count += 1\n",
    "        \n",
    "    patterns = []\n",
    "    for i in range(15):\n",
    "        patterns.append([np.array(raw_patterns[i][j]) for j in range(len(raw_patterns[i]))])\n",
    "    patterns = [np.concatenate(patterns[i],0) for i in range(15)]\n",
    "    \n",
    "    spikes = []\n",
    "    for i in range(15):\n",
    "        spikes.append([np.array(raw_spikes[i][j]) for j in range(len(raw_spikes[i]))])\n",
    "    spikes = [np.concatenate(spikes[i],0) for i in range(15)]\n",
    "    \n",
    "    f = h5py.File(filename,'w')\n",
    "    try:\n",
    "        for i in range(15):\n",
    "            data_group = f.create_group(\"Circuit_\" + str(i))\n",
    "            data_group.create_dataset(\"Patterns\", data=patterns[i])\n",
    "            data_group.create_dataset(\"Spikes\",   data=spikes[i])\n",
    "        f.close()\n",
    "    except:\n",
    "        print('')\n",
    "        print('!!!')\n",
    "        print('Failed to save the data properly.')\n",
    "        try:\n",
    "            f.close()\n",
    "        except:\n",
    "            print('Could not close the file.')\n",
    "        print('!!!')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pre  = \"filename_of_data_before_transformation_\"  # Should end with an underscore and not contain the 4 digit number or file ending (h5)\n",
    "file_post = \"filename_of_data_after_transformation.h5\" # Should contain the file ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data(file_pre,file_post,overwrite=False)     # Overwrites an old file, if overwrite=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
